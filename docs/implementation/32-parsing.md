## Parsing

Once we have generated a list of tokens (instances of `Token`) from the `Lexer` instance we need to turn these into a structure that represents our program's source code _but_ using in-memory data-structures which we can traverse and process at a later stage.

### Overview

The `Parser` class contains several methods for parsing different sub-structures of a TLang program and returning different data types generated by these methods. The parser has the ability to move back and forth between the token stream provided and fetch the current token (along with analysing it to return the type of symbol the token represents - known as the `SymbolType` (TODO: Cite the “Symbol types” section).

For example, the method `parseIf()` is used to parse if statements, it is called on the occurence of the token of `if`. This method returns an instance of type `IfStatement`. Then there are methods like `parseBody()` which is responsible for creating several sub-calls to methods such as `parseIf()` and building up a list of `Statement` instances (the top-type for all parser nodes).

The entry point to call is `parse()` which will return an instance of type `Module`.

!!! info
    The entry point handling may change soon with the advent of proper module support

### API

The API exposed by the parser is rather minimal as there isn't much to a parser than controlling the token stream pointer (the position in the token stream), fetching the token and acting upon the type or value of said token. Therefore we have the methods summarised below:

1. `nextToken()`
    * Moves the token pointer to the next token
2. `previousToken()`
    * Moves the token pointer to the previous token
3. `getCurrentToken()`
    * Returns the current `Token` instance at the current token pointer position
4. `hasTokens()`
    * Returns `true` if there are tokens still left in the stream (i.e. `tokenPtr < tokens.length`), `false` otherwise

### Initialization

The initialization of the parser is rather simple, an instance of the `Parser` class must be instantiated, along with this the following arguments must be provided to the constructor:

1. `Token[] tokens`
    * This is an array of `Token` to be provided to the parser for parsing. This would have been derived from the `Lexer` via its `performLex()` and `getTokens()` call.

A new instance woud therefore be created with something akin to:

```d
// Tokenize the following program
string sourceCode = "int i = 2;"
Lexer lexer = new Lexer(sourceCode);
lexer.performLex();

// Extract tokens and pass to the lexer
Token[] tokens = lexer.getTokens();
Parser parser = new Parser(tokens);
```

### Symbol types

The token stream is effectively a list of instances of `Token` which consist just of the token itself as a string and the coordinates of the token (where it occurs). However, some tokens, despite being different strings, can be of the same type or _syntactical grouping_. For example one would agree that both tokens `1.5` and `25.2` are both different tokens but are both floating points. This is where the notion of symbol types comes in.